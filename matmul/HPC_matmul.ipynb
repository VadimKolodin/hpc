{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем компилатор"
      ],
      "metadata": {
        "id": "5tTpBSwEH5v9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auZLC4RzHzbp",
        "outputId": "c256c182-546c-443c-e779-472151a882a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-vqr4fgjx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-vqr4fgjx\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=5c0f42b8ae0a3adadbae6ab98085e0a550981be527c5d5a9f304ed6e7a8b74d1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mrqwyzy6/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Непосредственно программа"
      ],
      "metadata": {
        "id": "aJAMmh7lH-5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cublas_v2.h>\n",
        "#include <malloc.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <stdexcept>\n",
        "using namespace std;\n",
        "/*\n",
        " Умножение матриц a(N1, M1) и b(N2, M2)\n",
        "*/\n",
        "__global__ void kernel(double* c, double* a, double* b, int N1, int M1, int N2, int M2) {\n",
        "\t//мысленно дробим матрицу на подматрицы размерами blockDim.x X blockDim.y и каждому потоку в блоке даем свой элемент результирующей матрицы\n",
        "  int ROW = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  int COL = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "\n",
        "  //проверяем что мы не вышли за размер матрицы\n",
        "  if (COL < M2 && ROW < N1) {\n",
        "      double sum  = 0;\n",
        "      for (int i = 0; i < M1; ++i) {\n",
        "          //printf(\"(%d,%d) += a[%d]*b[%d]\\n\", ROW, COL, ROW*M1 + i, N2 * i + COL);\n",
        "          //считаем рехультирующий элемент перемножением ROW строки на COL столбец\n",
        "          sum = sum+ a[ROW*M1 + i] * b[M2 * i + COL];\n",
        "      }\n",
        "      c[ROW * M2 + COL] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "void handle_cuda_result(cudaError_t cuerr, char msg[]) {\n",
        "    if (cuerr != cudaSuccess) {\n",
        "        fprintf(stderr, cudaGetErrorString(cuerr));\n",
        "        fprintf(stderr, \"\\n\");\n",
        "        throw runtime_error(msg);\n",
        "    }\n",
        "}\n",
        "\n",
        "/*\n",
        " Загрузка данных на GPU\n",
        " @ resultGpuPointer - перезаписывается, указатель на указатель на память GPU (чтобы значение указателя сохранялось)\n",
        " @ mat - указатель на массив с развернутой матрицей\n",
        " @ size - размер развернутой матрицы\n",
        "*/\n",
        "void upload_to_device(double** resultGpuPointer, double* mat, int size) {\n",
        "    int sizeInBytes = size * sizeof(double);\n",
        "    //выделяем память\n",
        "    cudaError_t cuerr = cudaMalloc((void**)resultGpuPointer, sizeInBytes);\n",
        "    handle_cuda_result(cuerr, \"Cannot allocate device array\");\n",
        "\n",
        "    // копируем массив\n",
        "    //*resultGpuPointer - разыменовываем указатель на указатель, чтобы передать указатель\n",
        "    cuerr = cudaMemcpy(*resultGpuPointer, mat, sizeInBytes, cudaMemcpyHostToDevice);\n",
        "    handle_cuda_result(cuerr, \"Cannot copy a array from host to device\");\n",
        "}\n",
        "\n",
        "/*\n",
        "Загрузка данных на хост-машину с GPU\n",
        " @ resultGpuPointer - указатель на память GPU\n",
        " @ gpuMatPointer - указатель на массив с развернутой матрицей, куда будет загружена матрица (память должная быть выделена)\n",
        " @ size - размер развернутой матрицы\n",
        "*/\n",
        "void download_from_device(double* gpuMatPointer, double* resultMat, int size) {\n",
        "    int sizeInBytes = size * sizeof(double);\n",
        "    // копируем массив\n",
        "    cudaError_t cuerr = cudaMemcpy(resultMat, gpuMatPointer, sizeInBytes, cudaMemcpyDeviceToHost);\n",
        "    handle_cuda_result(cuerr, \"Cannot copy a array from device to host\");\n",
        "}\n",
        "\n",
        "/*\n",
        "  Умножение матриц a(N1, M1) и b(N2, M2)\n",
        "*/\n",
        "double mat_mul_gpu(double* a, double* b, double* c, int N1, int M1, int N2, int M2, dim3 blocksPerGrid, dim3 threadsPerBlock){\n",
        "    cudaError_t cuerr;\n",
        "    // Выделение памяти на устройстве\n",
        "    double* aGpuPointer = NULL;\n",
        "\n",
        "    //передаем указатель на указатель, чтобы работать со значением указателя                                                                                                                ///\n",
        "    upload_to_device(&aGpuPointer, a, N1*M1);\n",
        "    double* bGpuPointer = NULL;\n",
        "    upload_to_device(&bGpuPointer, b, N2*M2);\n",
        "    double* cGpuPointer = NULL;\n",
        "    upload_to_device(&cGpuPointer, c, N1*M2);\n",
        "\n",
        "    // Создание обработчиков событий\n",
        "    cudaEvent_t start, stop;\n",
        "    float gpuTime = 0.0f;\n",
        "    cuerr = cudaEventCreate(&start);\n",
        "    handle_cuda_result(cuerr, \"Cannot create CUDA start event\");\n",
        "\n",
        "    cuerr = cudaEventCreate(&stop);\n",
        "    handle_cuda_result(cuerr, \"Cannot create CUDA stop event\");\n",
        "\n",
        "    cuerr = cudaEventRecord(start, 0);\n",
        "    handle_cuda_result(cuerr, \"Cannot record CUDA start event\");\n",
        "\n",
        "    //Запуск ядра\n",
        "    kernel <<< blocksPerGrid, threadsPerBlock >>> (cGpuPointer, aGpuPointer, bGpuPointer, N1, M1, N2, M2);\n",
        "    handle_cuda_result(cudaGetLastError(), \"Cannot launch CUDA kernel\");\n",
        "\n",
        "    // Синхронизация устройств\n",
        "    cuerr = cudaDeviceSynchronize();\n",
        "    handle_cuda_result(cudaGetLastError(), \"Cannot synchronize CUDA kernel\");\n",
        "\n",
        "    // Установка точки окончания\n",
        "    cuerr = cudaEventRecord(stop, 0);\n",
        "    handle_cuda_result(cuerr, \"Cannot record CUDA stop event\");\n",
        "\n",
        "    // Копирование результата на хост\n",
        "    download_from_device(cGpuPointer, c, N1*M2);\n",
        "\n",
        "    cuerr = cudaEventElapsedTime(&gpuTime, start, stop);\n",
        "    handle_cuda_result(cuerr, \"Cannot get elapsed time\");\n",
        "    double time = gpuTime/ 1000;\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "    cudaFree(aGpuPointer);\n",
        "    cudaFree(bGpuPointer);\n",
        "    cudaFree(cGpuPointer);\n",
        "    return time;\n",
        "}\n",
        "\n",
        "\n",
        "void count_cuda_dims(dim3& blocksPerGrid, dim3& threadsPerBlock, int N1, int M1, int N2, int M2) {\n",
        "    //максимум потоков в блоке - 1024\n",
        "    int xthreadsPerBlock = N1 < 32 ? N1 : 32;\n",
        "    int ythreadsPerBlock = M2 < 32 ? M2 : 32;\n",
        "    int xblocksPerGrid = ceil((float)N1 / xthreadsPerBlock);\n",
        "    int yblocksPerGrid = ceil((float)M2 / ythreadsPerBlock);\n",
        "    printf(\"grid(%d, %d) block(%d,%d)\\n\", xblocksPerGrid, yblocksPerGrid, xthreadsPerBlock, ythreadsPerBlock);\n",
        "    blocksPerGrid =  dim3(xblocksPerGrid, yblocksPerGrid, 1);\n",
        "    threadsPerBlock =  dim3(xthreadsPerBlock, ythreadsPerBlock, 1);\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "double mat_mul_cpu(double* a, double* b, double* c, int N1, int M1, int N2, int M2){\n",
        "  double time = clock();\n",
        "\tfor (int i = 0; i < N1; ++i) {\n",
        "    for (int j = 0; j < M2; ++j) {\n",
        "\t\t  double sum = 0;\n",
        "      for (int k = 0; k < M1; ++k) {\n",
        "        sum = sum+ a[i*M1 + k] * b[M2 * k + j];\n",
        "\t\t  }\n",
        "\t\t  c[i * M2 + j] = sum;\n",
        "    }\n",
        "  }\n",
        "  time = clock() - time;\n",
        "  time/=CLOCKS_PER_SEC;\n",
        "  return time;\n",
        "}\n",
        "\n",
        "void fill_mat(double* mat, int n, int m) {\n",
        "    srand (time(NULL));\n",
        "    double re, im;\n",
        "    for(int i = 0; i < n * m; ++i) {\n",
        "        mat[i] = rand()/10000000.0;\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "void check_mat(double* cpu, double* gpu,  int n, int m, double precision) {\n",
        "  for (int i = 0; i < n; ++i) {\n",
        "    for (int j = 0; j < m; ++j) {\n",
        "      if (fabs(cpu[i*m+j] - gpu[i*m+j]) > precision) {\n",
        "          fprintf(stderr, \"Матрицы не равны: cpu(%d,%d)=%f; gpu(%d,%d)=%f\\n\", i,j, cpu[i*m+j], i,j, gpu[i*m+j]);\n",
        "          throw runtime_error(\"Матрицы не равны\");\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "    int an = 2048; int am = 2048;\n",
        "    int bn = 2048; int bm = 2048;\n",
        "    int cn = an; int cm = bm;\n",
        "    double* a = (double*) malloc(an*am*sizeof(double));\n",
        "    double* b = (double*) malloc(bn*bm*sizeof(double));\n",
        "    double* c_gpu = (double*) malloc(cn*cm*sizeof(double));\n",
        "\t  double* c_cpu = (double*) malloc(cn*cm*sizeof(double));\n",
        "\n",
        "    fill_mat(a, an, am);\n",
        "    fill_mat(b, bn, bm);\n",
        "\n",
        "    dim3 threadsPerBlock;\n",
        "    dim3 blocksPerGrid;\n",
        "\n",
        "    count_cuda_dims(blocksPerGrid, threadsPerBlock, an,am,bn,bm);\n",
        "\n",
        "    double timeGpu = mat_mul_gpu(a,b,c_gpu, an,am,bn,bm, blocksPerGrid, threadsPerBlock);\n",
        "    printf(\"GPU: %f\\n\", timeGpu);\n",
        "\n",
        "    double timeCpu = mat_mul_cpu(a,b,c_cpu, an,am,bn,bm);\n",
        "    printf(\"CPU: %f\\n\", timeCpu);\n",
        "\n",
        "    check_mat(c_cpu, c_gpu, cn, cm, 0.000001);\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlNNP2zOH-Pp",
        "outputId": "cf14fcf4-194e-4b1f-bfe8-0939a7b77659"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid(64, 64) block(32,32)\n",
            "GPU: 0.475556\n",
            "CPU: 135.858048\n",
            "\n"
          ]
        }
      ]
    }
  ]
}