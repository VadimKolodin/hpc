# Произведение матриц
Лабораторная работа выполнена на c++, в среде Colab. 
(На данный момент не могу выполнять на своей машине, покольку у меня конфликты версий CUDA и Visual Studio, 
сносить что-либо из этого пока боюсь, тк НИР выполняю на tensorflow с CUDA+cuDNN, очень шаткое равновесие версий у самого Tensorflow,
ломается от любого чиха в его сторону).

Распаралелен был подсчет каждого элемента в результирующей матрице, т.е. каждый поток подсчитывает свой эелемент.

Выбрана 2D топология блоков и их сетки, поскольку в таком случае алгоритм становится интуитивно понятным.
Размеры блока и сетки выбираются автоматически исходя из разрешенных пределов и скорости выполнения. 
(Все потоки в блоке гаранитрованно выполняются одновременно, поэтому стараемся выбрать максимально возможный размер - 32x32x1 = 1024)

Время представлено усредненное по 36 запускам
#Эксперименты 1
Матрица А  	| Матрица Б | Время выполнения GPU, мс 	| Время выполнения CPU, мс 
----------- | --------- | -------------------------	| -----------------------
128х128  	| 128х128	| 0,262 					| 6,723
256х256  	| 256х256	| 1,934						| 66,935
512х512  	| 512х512 	| 12,458 					| 946,288
1024х1024	| 1024х1024	| 44,664 					| 8145,409
2048х2048	| 2048х2048	| 286,343					| 134558,527

![](//cpu.png)
![](//gpu.png)
Из таблицы видно, что рост времени выполнения с увеличением размера для CPU более чем кубический, что обсуловлено вычислительной сложностью алгоритма ijk - O(n^3). 
С ростом размера матрицы также увеличивается и рост скорости выполнения, 
поскольку все больше становятся заметно время выполнения "быстрых" вспомогательных операции - присвоения и операций для работы цикла.
В то время как для GPU рост времени - чуть более чем квадратичный, хотя каждому потоку необходимо выполнять O(n) операций. Это можно объяснить тем, 
что одновременное выполнение потоков в разных блоках не гарантировано, что, скорее всего и происходит.
Более того, вспомогательные операции тут не играют большой роли, из-за того, что их не так много 
(если представить, что весь алгоритм, это подсчет одного элемента, при условии выполнения всех нитей одновременно).
![](//acceleration.png)
График ускорения выглядит линейно, из-за стабильного роста времени выполнения с ростом количества элементов, как для параллельной, так и последовательной программы.
Тем не менее, ускорение в n^2 раз не достигнуто, поскольку не все блоки, а значит и не все нити, выполняются одновременно.

#Эксперименты 2
Матрица А  	| Матрица Б | Время выполнения GPU, мс 	| Время выполнения CPU, мс 
----------- | --------- | -------------------------	| -----------------------
256х512  	| 512х256	| 1,279						| 187,496
512х256  	| 256х512 	| 2,212 					| 403,477
512х1024	| 1024х512	| 21,579 					| 2601,783
1024х512	| 512х1024	| 26,869 					| 3677,254
1024х2048	| 2048х1024	| 25,941 					| 26352,826
2048х1024	| 1024х2048	| 48,007 					| 33762,457

Во второй серии экспериментов проверено время работы алгоритмов для неквадратных матриц A(n1,m1) и B(n2,m2), m1=n2.
Теоритически, время работы алгоритма ijk O(n1*m2*m1) = (кол-во элементов * операций сложений+умножений для каждого элемента результирующей матрицы), для параллельного O(m1).
Для неквадратных матриц сразу играет роль размерности матриц, например перемножение матриц с размерами 512х1024 * 1024х512 и матриц с размерами 1024х512 * 512х1024
предполагает различное количество операций, при одинаковом количестве элементов у каждой матрицы.
Сразу видно, что время работы как для параллельной, так и для  последовательной программ выше, если результирующая матрица имеет бОльшую размерность при одинаковом количестве элементов у исходных матриц.
Также, видно, что для строк таблицы 2, 4, 6, где размерность итоговой матрицы больше (а значит большеи количесвто потоков), ускорение выше (из-за большего количества одновременно работающих нитей).
Тем не менее, для матриц из строк 2, 6 время выполнение параллельной программы заняло времени примерно в 2 раза больше, чем для аналогичных матриц из строк 1, 5 что и должно случится судя по теоритической оценке алгоритма.
Однако для матриц 512х1024 * 1024х512 и 1024х512 * 512х1024 время выполнения параллельной программы практически одинаковое
(не могу понять почему, возможно из-за максимального порога одновременно исполняемых блоков у тестируемой видеокарты).